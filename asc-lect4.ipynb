{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân lớp ảnh dùng Keras với VGG16 (pretrained-model)\n",
    "\n",
    "Ví dụ sau minh hoạ một ứng dụng phân lớp ảnh (image classification).\n",
    "\n",
    "Ứng dụng sử dụng thư viện Keras, với bộ phân lớp (classifier) đã được huấn luyện sẵn \n",
    "dùng mạng neural VGG16. Bộ dữ liệu dùng để huấn luyện là ImageNet-1K - có 1,000 nhãn (label).\n",
    "\n",
    "Kết quả trả về là xác suất (prob) của từng nhãn - xác suất càng lớn - khả năng nhãn được gán càng cao.\n",
    "\n",
    "Một demo tương tự có thể xem tại website: http://goliath.liacs.nl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# written by B2DL \n",
    "# adapted from https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from skimage import  io\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# load image from URL - dùng skimage (opencv không hỗ trợ)\n",
    "#url = 'http://k14.vcmedia.vn/2016/5-1461127393310.jpg'\n",
    "url = 'http://farm1.static.flickr.com/116/265424705_d835d8dacb.jpg'\n",
    "img = io.imread(url)\n",
    "img_name = 'test-vgg16-keras.jpg'\n",
    "cv2.imwrite(img_name, cv2.cvtColor(img, cv2.COLOR_RGB2BGR)) \n",
    "\n",
    "# đọc ảnh từ file\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(img_name)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "\n",
    "# load the model \n",
    "# The first time you run this example, \n",
    "# Keras will download the weight files from the Internet \n",
    "# and store them in the ~/.keras/models directory.\n",
    "model = VGG16()\n",
    "\n",
    "# load an image from file\n",
    "image = load_img(img_name, target_size=(224, 224))\n",
    "\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "\n",
    "# reshape data for the model \n",
    "# The network expects one or more images as input; \n",
    "# that means the input array will need to be 4-dimensional: \n",
    "# samples, rows, columns, and channels.\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "# prepare the image for the VGG model\n",
    "# the only preprocessing we do is subtracting the mean RGB value, \n",
    "# computed on the training set, from each pixel.\n",
    "# Keras provides a function called preprocess_input() to prepare new input for the network.\n",
    "image = preprocess_input(image)\n",
    "\n",
    "# predict the probability across all output classes\n",
    "# call the predict() function on the model \n",
    "# in order to get a prediction of the probability \n",
    "# of the image belonging to each of the 1000 known object types.\n",
    "yhat = model.predict(image)\n",
    "\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat, top=5)[0]\n",
    "print('Predicted (labelID, labelName, prob):', label)\n",
    "\n",
    "# print deep model\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
